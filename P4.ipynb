{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the image from the source folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "test_images=os.listdir('./test_images')\n",
    "image=test_images[3]\n",
    "img=cv2.imread('./test_images/'+image)\n",
    "gray_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Calibrate and undistort the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cal_undistort_image(img, objPts = objpoints, imgPts = imgpoints):\n",
    "    \"\"\"\n",
    "    returns the undistorted image\n",
    "    \"\"\"\n",
    "    ret,camera_matrix,distortion_coefficients,rotational_vectors,tangential_vectors=cv2.calibrateCamera(objPts,imgPts,gray_img.shape[0:2],None,None)\n",
    "    undistort_img = cv2.undistort(img,camera_matrix,distortion_coefficients,None,camera_matrix)\n",
    "    return undistort_img\n",
    "\n",
    "def hls_to_s(img):\n",
    "    \"\"\"\n",
    "    returns a 2D image ie the s channel of the HLS image\n",
    "    \"\"\"\n",
    "    hls=cv2.cvtColor(img,cv2.COLOR_BGR2HLS) \n",
    "    mask=np.zeros_like(hls[:,:,0])\n",
    "    #thresholding the pixel values of the mask\n",
    "    mask[(hls[:,:,2] > 100) & (hls[:,:,0]<100)]=1\n",
    "    s_channel=mask\n",
    "    return s_channel\n",
    "\n",
    "def absolute_sobel(img,orientation='x',sobel_kernel=3,thresh=(20,100)):\n",
    "    \"\"\"\n",
    "    returns a binary thresholded image with sobel gradients\n",
    "    \"\"\"\n",
    "    #taking sobel gradient \n",
    "    if orientation=='x':\n",
    "        sobel_img=cv2.Sobel(img,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    elif orientation=='y':\n",
    "        sobel_img=cv2.Sobel(img,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    #finding the absolute value     \n",
    "    abs_sobel=np.absolute(sobel_img) \n",
    "    #scaling the pixel values to 8 bit\n",
    "    scaled_sobel_img=np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    #create a binary image with zero values\n",
    "    binary_threshold=np.zeros_like(scaled_sobel_img)\n",
    "    # change the zero values to ones where thresholding condition is met\n",
    "    binary_threshold[(scaled_sobel_img >= thresh[0]) & (scaled_sobel_img <= thresh[1])]=1\n",
    "    return binary_threshold\n",
    "\n",
    "def mag_thresh(img,sobel_kernel=5,thresh=(30,100)):\n",
    "    \"\"\"\n",
    "    This returns the binary thresholded image with both x and y sobel gradients\n",
    "    \"\"\"\n",
    "    #taking sobel x gradient\n",
    "    sobelx=cv2.Sobel(img,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    #taking sobel y gradient\n",
    "    sobely=cv2.Sobel(img,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    #calculating the gradient magnitude\n",
    "    abs_mag_sobel=np.absolute(np.sqrt(sobelx**2 + sobely**2))\n",
    "    #scaling the pixel values to 8 bit\n",
    "    scaled_sobel=np.uint8(255*abs_mag_sobel/np.max(abs_mag_sobel))\n",
    "    #create a binary image with zero values\n",
    "    binary_threshold=np.zeros_like(scaled_sobel)\n",
    "    # change the zero values to ones where thresholding condition is met\n",
    "    binary_threshold[(scaled_sobel >= thresh[0]) & (scaled_sobel <=thresh[1])]=1\n",
    "    return binary_threshold\n",
    "\n",
    "def dir_thresh(img,sobel_kernel=5,thresh=(0.7,1.3)):\n",
    "    \"\"\"\n",
    "    This returns the binary image with thresholded angled sobel gradients\n",
    "    \"\"\"\n",
    "    #taking sobel x gradient\n",
    "    sobelx=cv2.Sobel(img,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    #taking sobel y gradient\n",
    "    sobely=cv2.Sobel(img,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    #getting the sobel gradients based on the direction\n",
    "    dir_grad=np.arctan2(np.absolute(sobely),np.absolute(sobelx))\n",
    "    #create a binary image with zero values\n",
    "    binary_threshold=np.zeros_like(dir_grad)\n",
    "    # change the zero values to ones where thresholding condition is met\n",
    "    binary_threshold[(dir_grad >= thresh[0]) & (dir_grad <=thresh[1] )]=1\n",
    "    return binary_threshold\n",
    "\n",
    "def perform_perspective_transform(img,img_size):\n",
    "    \"\"\"\n",
    "    This returns the warped image ie a bird's eye view \n",
    "    \"\"\"\n",
    "    #the source coordinates on the image to be taken in consideration for a transform\n",
    "    src = np.array([[585, 460], [203, 720], [1127, 720], [695, 460]]).astype(np.float32)\n",
    "    #the sestination coordinates on the image to be taken in consideration for warping\n",
    "    dst = np.array([[320, 0], [320, 720], [960, 720], [960, 0]]).astype(np.float32)\n",
    "    #returns a transform matrix M\n",
    "    M=cv2.getPerspectiveTransform(src,dst)\n",
    "    #a warped image is returned\n",
    "    warped=cv2.warpPerspective(img,M,img_size,flags=cv2.INTER_LINEAR)\n",
    "    return warped\n",
    " \n",
    "def perform_inverse_perspective_transform(img,img_size):\n",
    "    \"\"\"\n",
    "    This returns the original image from the transformed image\n",
    "    \"\"\"\n",
    "    src = np.array([[585, 460], [203, 720], [1127, 720], [695, 460]]).astype(np.float32)\n",
    "    dst = np.array([[320, 0], [320, 720], [960, 720], [960, 0]]).astype(np.float32)\n",
    "    M=cv2.getPerspectiveTransform(dst,src)\n",
    "    #the original image is returned\n",
    "    original=cv2.warpPerspective(img,M,img_size,flags=cv2.INTER_LINEAR)\n",
    "    return original    \n",
    "\n",
    "\n",
    "def hls_sobel_mask(img):\n",
    "    \"\"\"\n",
    "     Applies the HLS and sobel masks to the image\n",
    "    \"\"\"\n",
    "    #take a copy of the image\n",
    "    img = img.copy()\n",
    "    #convert image to grayscale\n",
    "    gray_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #convert image to HLS\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    # Apply a mask on HLS colour channels\n",
    "    mask = np.zeros_like(hls[:, :, 0])\n",
    "    # This selects pixels with higher than 100 saturation and lower than 100 hue\n",
    "    mask[((hls[:, :, 2] > 100) & (hls[:, :, 0] < 100) ) ] = 1\n",
    "    # Apply a sobel magnitude threshold\n",
    "    # I apply a more lenient mag_thresh to the upper part of the transformed image, as this part is blurrier\n",
    "    # and will therefore have smoother gradients.\n",
    "    # On the bottom half, this selects pixels with >10 sobel magnitude, and on the top half, \n",
    "    # selects pixels with >35 sobel magnitude\n",
    "    upper_mag = mag_thresh(gray_img, 3, (10, 255))\n",
    "    lower_mag = mag_thresh(gray_img, 3, (35, 255))\n",
    "    \n",
    "    mag_mask = np.zeros_like(lower_mag)\n",
    "    mag_mask[:int(mag_mask.shape[0]/2), :] = upper_mag[:int(mag_mask.shape[0]/2), :]\n",
    "    mag_mask[int(mag_mask.shape[0]/2):, :] = lower_mag[int(mag_mask.shape[0]/2):, :]\n",
    "    \n",
    "    # Use the bitwise OR mask of both masks for the final mask\n",
    "    final_mask = np.maximum(mag_mask, mask)\n",
    "\n",
    "    # Return the transformed mask\n",
    "    return final_mask                        \n",
    "\n",
    "def find_peaks(final_mask):\n",
    "    \"\"\"\n",
    "    Returns the inices of the left and right lanes\n",
    "    \"\"\"\n",
    "    #finding the size of the image\n",
    "    shape=final_mask.shape\n",
    "    #taking the bottom section of image under consideration\n",
    "    bottom_section=final_mask[-int(shape[0]/2):,]\n",
    "    \n",
    "    \n",
    "    #the left peak ie the indices or x position of left lane\n",
    "    left_peak=bottom_section[:,:int(shape[1]/2)].sum(axis=0).argmax()\n",
    "    #the right peak ie the indices or the x position of right lane\n",
    "    right_peak=bottom_section[:,int(shape[1]/2):].sum(axis=0).argmax() + int(shape[1]/2)\n",
    "\n",
    "    return left_peak,right_peak\n",
    "                        \n",
    "def window_search(final_mask,left_peak,right_peak,no_of_strips=10,margin=80):\n",
    "    \"\"\"\n",
    "    This applies the sliding window approach to find lane pixels, and then fits a polynomial to the found pixels.\n",
    "    \"\"\"\n",
    "    #creating an array of windows or strips ie dividing the image into vertical windows or strips\n",
    "    strips=[]\n",
    "    assert final_mask.shape[0] % no_of_strips==0 , 'No of strips should be a factor of height of the image ie vertical resolution'\n",
    "    #size or width of the strip\n",
    "    width_of_strip=final_mask.shape[0]/no_of_strips\n",
    "    for i in range(no_of_strips):\n",
    "        strip=final_mask[i*width_of_strip:(i+1)*width_of_strip,:]\n",
    "        strips.append(strip)\n",
    "    # reverse theorder of strips ie start from the bottom to top        \n",
    "    strips=strips[::-1]\n",
    "    #store x positions of left lane \n",
    "    lefts=[left_peak]\n",
    "    #store x positions of right lane \n",
    "    rights=[right_peak]\n",
    "    left_px=[]\n",
    "    left_py=[]\n",
    "    right_px=[]\n",
    "    right_py =[]\n",
    "    for i ,strip in enumerate(strips):\n",
    "        offset=(no_of_strips -i-1)*width_of_strip\n",
    "        last_left=int(lefts[-1])\n",
    "        last_right=int(rights[-1])\n",
    "        # Only consider pixels within +-leeway of last strip location\n",
    "        temp_left_strip=strip.copy()\n",
    "        temp_left_strip[:, :last_left-margin]=0\n",
    "        temp_left_strip[:,last_left+margin:]=0\n",
    "        \n",
    "        temp_right_strip=strip.copy()\n",
    "        temp_right_strip[:,:last_right-margin]=0\n",
    "        temp_right_strip[:,last_right+margin:]=0\n",
    "        # Save the x, y pixel indexes for calculating the polynomial\n",
    "        left_px.append(temp_left_strip.nonzero()[1])\n",
    "        left_py.append(temp_left_strip.nonzero()[0] + offset)\n",
    "        \n",
    "        right_px.append(temp_right_strip.nonzero()[1])\n",
    "        right_py.append(temp_right_strip.nonzero()[0] + offset)\n",
    "    # Create x and y indice arrays for both lines\n",
    "    left_px=np.concatenate(left_px)\n",
    "    left_py=np.concatenate(left_py)\n",
    "    right_px=np.concatenate(right_px)\n",
    "    right_py=np.concatenate(right_py)\n",
    "    # Fit the polynomials!\n",
    "    left_poly=np.polyfit(left_py,left_px,2)\n",
    "    right_poly=np.polyfit(right_py,right_px,2)\n",
    "    \n",
    "    return left_poly,right_poly\n",
    "\n",
    "def plot_polygon(img_original,img_size,left_poly,right_poly):\n",
    "    \"\"\"\n",
    "    Plot the polygon on the images\n",
    "    \"\"\"\n",
    "    plot_y=np.linspace(0,img_original.shape[0]-1,img_original.shape[0])\n",
    "    left_fit=left_poly[0]*plot_y**2 + left_poly[1]*plot_y + left_poly[2]\n",
    "    right_fit=right_poly[0]*plot_y**2 +right_poly[1]*plot_y + right_poly[2]\n",
    "    \n",
    "    pts_left=np.array([np.transpose(np.vstack([left_fit,plot_y]))])\n",
    "    pts_right=np.array([np.flipud(np.transpose(np.vstack([right_fit,plot_y])))])\n",
    "    pts=np.hstack((pts_left,pts_right))\n",
    "    # Create an overlay from the lane lines\n",
    "    overlay_mask=np.zeros_like(img_original).astype(np.uint8)\n",
    "   \n",
    "    cv2.fillPoly(overlay_mask,np.int_([pts]),(0,255,0))\n",
    "    # Apply inverse transform to the overlay to plot it on the original road\n",
    "    overlay_mask=perform_inverse_perspective_transform(overlay_mask,img_size)\n",
    "    \n",
    "    return cv2.addWeighted(img_original,1,overlay_mask,0.3,0)\n",
    "\n",
    "def find_curvature(poly,final_mask):\n",
    "    yscale = 30 / 720 # Real world metres per y pixel\n",
    "    xscale = 3.7 / 700 # Real world metres per x pixel\n",
    "    \n",
    "    # Convert polynomial to set of points for refitting\n",
    "    ploty = np.linspace(0, final_mask.shape[0]-1, final_mask.shape[0])\n",
    "    fitx = poly[0] * ploty ** 2 + poly[1] * ploty + poly[2]\n",
    "    \n",
    "    # Fit new polynomial\n",
    "    fit_cr = np.polyfit(ploty * yscale, fitx * xscale, 2)\n",
    "    \n",
    "    # Calculate curve radius\n",
    "    curverad = ((1 + (2 * fit_cr[0] * np.max(ploty) * yscale + fit_cr[1]) ** 2) ** 1.5) / np.absolute(2 * fit_cr[0])\n",
    "    return curverad\n",
    "\n",
    "def find_offset(l_poly,r_poly):\n",
    "    #assuming camera is installed at the center of the car dashboard\n",
    "    lane_width=3.7 #in metres\n",
    "    h=720\n",
    "    w=1280\n",
    "    bottom_point_left=l_poly[0]*h**2 + l_poly[1]*h + l_poly[2]\n",
    "    bottom_point_right=r_poly[0]*h**2 + r_poly[1]*h + r_poly[2]\n",
    "    \n",
    "    # no of pixels per metre\n",
    "    meter_scale=lane_width/np.absolute(bottom_point_right -bottom_point_left)\n",
    "    \n",
    "    #midpoint in between  the lanes\n",
    "    midpoint=np.mean([bottom_point_left,bottom_point_right])\n",
    "    \n",
    "    #offset between the camera and the lane center\n",
    "    \n",
    "    offset=(w/2 - midpoint) * meter_scale\n",
    "    \n",
    "    return offset\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_rad=None\n",
    "last_left_poly=None\n",
    "last_right_poly=None\n",
    "def process_frame(img):\n",
    "    global last_rad,last_left_poly,last_right_poly\n",
    "    \n",
    "    #weights for smoothing\n",
    "    rad_factor=0.03\n",
    "    poly_factor=0.3\n",
    "    \n",
    "    #undistorting the frame image\n",
    "    undistort=cal_undistort_image(img) \n",
    "   \n",
    "    #create image copy\n",
    "    orig_img=undistort.copy()\n",
    "    \n",
    "    img_size=(undistort.shape[1],undistort.shape[0])\n",
    "    #perform warping of the image\n",
    "    warped=perform_perspective_transform(undistort,img_size)\n",
    "    \n",
    "    combined_binary_thresh =hls_sobel_mask(warped)\n",
    "    \n",
    "    #finding the lane lines x positions\n",
    "    l,r=find_peaks(combined_binary_thresh)#\n",
    "    #finding the coefficeints of polynomials fitting the lane lines\n",
    "    l_poly,r_poly = window_search(combined_binary_thresh,l,r)\n",
    "    \n",
    "    \n",
    "    if last_left_poly is None:\n",
    "        last_left_poly=l_poly\n",
    "        last_right_poly=r_poly\n",
    "    else:\n",
    "        l_poly=(1-poly_factor)* last_left_poly + (poly_factor) * l_poly\n",
    "        r_poly=(1-poly_factor)*last_right_poly +(poly_factor) * r_poly\n",
    "        last_left_poly=l_poly\n",
    "        last_right_poly=r_poly\n",
    "    \n",
    "    #finding the curvature of the road\n",
    "    \n",
    "    l_rad=find_curvature(l_poly,combined_binary_thresh)\n",
    "    r_rad=find_curvature(r_poly,combined_binary_thresh)\n",
    "    rad=np.mean([l_rad,r_rad])\n",
    "    \n",
    "    if last_rad is None:\n",
    "        last_rad=rad\n",
    "    else:\n",
    "        rad=(1-rad_factor) *rad + rad_factor * last_rad\n",
    "    #plot the polygon\n",
    "    result=plot_polygon(orig_img, (combined_binary_thresh.shape[1],combined_binary_thresh.shape[0]),l_poly,r_poly)\n",
    "    \n",
    "     # Write radius on image\n",
    "    cv2.putText(result, 'Lane Radius: {}m'.format(int(last_rad)), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, 255)\n",
    "    offset=find_offset(l_poly,r_poly)\n",
    "    \n",
    "    #Write lane offset on frame\n",
    "    cv2.putText(result,'Lane Offset: {}m'.format(int(offset)),(10,100),cv2.FONT_HERSHEY_SIMPLEX,1.5,255)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Me\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\ipykernel\\__main__.py:158: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[194, 158, 112],\n",
       "        [194, 158, 112],\n",
       "        [194, 158, 112],\n",
       "        ..., \n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[193, 157, 111],\n",
       "        [194, 158, 112],\n",
       "        [194, 158, 112],\n",
       "        ..., \n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[193, 157, 111],\n",
       "        [194, 158, 112],\n",
       "        [194, 158, 112],\n",
       "        ..., \n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       ..., \n",
       "       [[ 78,  86, 106],\n",
       "        [ 84,  92, 112],\n",
       "        [ 88,  97, 117],\n",
       "        ..., \n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[ 79,  88, 108],\n",
       "        [ 82,  91, 111],\n",
       "        [ 86,  95, 115],\n",
       "        ..., \n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[ 80,  89, 109],\n",
       "        [ 79,  88, 108],\n",
       "        [ 79,  88, 108],\n",
       "        ..., \n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_frame(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_run4.mp4\n",
      "[MoviePy] Writing video project_video_run4.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                 | 0/1261 [00:00<?, ?it/s]\n",
      "  0%|                                         | 1/1261 [00:00<14:06,  1.49it/s]\n",
      "  0%|                                         | 2/1261 [00:01<13:07,  1.60it/s]\n",
      "  0%|                                         | 3/1261 [00:01<12:43,  1.65it/s]\n",
      "  0%|▏                                        | 4/1261 [00:02<11:48,  1.77it/s]\n",
      "  0%|▏                                        | 5/1261 [00:02<11:44,  1.78it/s]\n",
      "  0%|▏                                        | 6/1261 [00:03<10:49,  1.93it/s]\n",
      "  1%|▏                                        | 7/1261 [00:03<10:12,  2.05it/s]\n",
      "  1%|▎                                        | 8/1261 [00:03<09:31,  2.19it/s]\n",
      "  1%|▎                                        | 9/1261 [00:04<09:14,  2.26it/s]\n",
      "  1%|▎                                       | 10/1261 [00:04<09:00,  2.32it/s]\n",
      "  1%|▎                                       | 11/1261 [00:05<08:41,  2.40it/s]\n",
      "  1%|▍                                       | 12/1261 [00:05<08:44,  2.38it/s]\n",
      "  1%|▍                                       | 13/1261 [00:06<08:42,  2.39it/s]\n",
      "  1%|▍                                       | 14/1261 [00:06<08:55,  2.33it/s]\n",
      "  1%|▍                                       | 15/1261 [00:06<08:28,  2.45it/s]\n",
      "  1%|▌                                       | 16/1261 [00:07<08:15,  2.51it/s]\n",
      "  1%|▌                                       | 17/1261 [00:07<08:11,  2.53it/s]\n",
      "  1%|▌                                       | 18/1261 [00:08<08:57,  2.31it/s]\n",
      "  2%|▌                                       | 19/1261 [00:08<08:24,  2.46it/s]\n",
      "  2%|▋                                       | 20/1261 [00:08<08:49,  2.34it/s]\n",
      "  2%|▋                                       | 21/1261 [00:09<08:38,  2.39it/s]\n",
      "  2%|▋                                       | 22/1261 [00:09<08:43,  2.37it/s]\n",
      "  2%|▋                                       | 23/1261 [00:10<08:47,  2.35it/s]\n",
      "  2%|▊                                       | 24/1261 [00:10<09:29,  2.17it/s]\n",
      "  2%|▊                                       | 25/1261 [00:11<09:24,  2.19it/s]\n",
      "  2%|▊                                       | 26/1261 [00:11<09:38,  2.13it/s]\n",
      "  2%|▊                                       | 27/1261 [00:12<08:58,  2.29it/s]\n",
      "  2%|▉                                       | 28/1261 [00:12<08:39,  2.37it/s]\n",
      "  2%|▉                                       | 29/1261 [00:12<08:22,  2.45it/s]\n",
      "  2%|▉                                       | 30/1261 [00:13<08:00,  2.56it/s]\n",
      "  2%|▉                                       | 31/1261 [00:13<07:56,  2.58it/s]\n",
      "  3%|█                                       | 32/1261 [00:13<07:46,  2.64it/s]\n",
      "  3%|█                                       | 33/1261 [00:14<07:33,  2.71it/s]\n",
      "  3%|█                                       | 34/1261 [00:14<07:33,  2.70it/s]\n",
      "  3%|█                                       | 35/1261 [00:14<07:33,  2.70it/s]\n",
      "  3%|█▏                                      | 36/1261 [00:15<07:32,  2.71it/s]\n",
      "  3%|█▏                                      | 37/1261 [00:15<07:29,  2.73it/s]\n",
      "  3%|█▏                                      | 38/1261 [00:16<07:21,  2.77it/s]\n",
      "  3%|█▏                                      | 39/1261 [00:16<07:28,  2.73it/s]\n",
      "  3%|█▎                                      | 40/1261 [00:16<07:21,  2.76it/s]\n",
      "  3%|█▎                                      | 41/1261 [00:17<07:26,  2.73it/s]\n",
      "  3%|█▎                                      | 42/1261 [00:17<07:34,  2.68it/s]\n",
      "  3%|█▎                                      | 43/1261 [00:17<07:52,  2.58it/s]\n",
      "  3%|█▍                                      | 44/1261 [00:18<08:10,  2.48it/s]\n",
      "  4%|█▍                                      | 45/1261 [00:18<08:10,  2.48it/s]\n",
      "  4%|█▍                                      | 46/1261 [00:19<08:46,  2.31it/s]\n",
      "  4%|█▍                                      | 47/1261 [00:19<08:42,  2.32it/s]\n",
      "  4%|█▌                                      | 48/1261 [00:20<08:25,  2.40it/s]\n",
      "  4%|█▌                                      | 49/1261 [00:20<08:24,  2.40it/s]\n",
      "  4%|█▌                                      | 50/1261 [00:20<08:11,  2.46it/s]\n",
      "  4%|█▌                                      | 51/1261 [00:21<08:17,  2.43it/s]\n",
      "  4%|█▋                                      | 52/1261 [00:21<08:11,  2.46it/s]\n",
      "  4%|█▋                                      | 53/1261 [00:22<08:50,  2.28it/s]\n",
      "  4%|█▋                                      | 54/1261 [00:22<08:43,  2.31it/s]\n",
      "  4%|█▋                                      | 55/1261 [00:23<08:18,  2.42it/s]\n",
      "  4%|█▊                                      | 56/1261 [00:23<08:43,  2.30it/s]\n",
      "  5%|█▊                                      | 57/1261 [00:23<08:39,  2.32it/s]\n",
      "  5%|█▊                                      | 58/1261 [00:24<08:30,  2.36it/s]\n",
      "  5%|█▊                                      | 59/1261 [00:24<08:16,  2.42it/s]\n",
      "  5%|█▉                                      | 60/1261 [00:25<08:11,  2.44it/s]\n",
      "  5%|█▉                                      | 61/1261 [00:25<09:58,  2.01it/s]\n",
      "  5%|█▉                                      | 62/1261 [00:26<10:11,  1.96it/s]\n",
      "  5%|█▉                                      | 63/1261 [00:26<09:53,  2.02it/s]\n",
      "  5%|██                                      | 64/1261 [00:27<10:18,  1.94it/s]\n",
      "  5%|██                                      | 65/1261 [00:27<10:27,  1.91it/s]\n",
      "  5%|██                                      | 66/1261 [00:28<09:35,  2.08it/s]\n",
      "  5%|██▏                                     | 67/1261 [00:28<08:57,  2.22it/s]\n",
      "  5%|██▏                                     | 68/1261 [00:29<08:28,  2.34it/s]\n",
      "  5%|██▏                                     | 69/1261 [00:29<08:22,  2.37it/s]\n",
      "  6%|██▏                                     | 70/1261 [00:29<08:14,  2.41it/s]\n",
      "  6%|██▎                                     | 71/1261 [00:30<07:59,  2.48it/s]\n",
      "  6%|██▎                                     | 72/1261 [00:30<07:59,  2.48it/s]\n",
      "  6%|██▎                                     | 73/1261 [00:31<07:47,  2.54it/s]\n",
      "  6%|██▎                                     | 74/1261 [00:31<07:43,  2.56it/s]\n",
      "  6%|██▍                                     | 75/1261 [00:31<07:45,  2.55it/s]\n",
      "  6%|██▍                                     | 76/1261 [00:32<07:54,  2.50it/s]\n",
      "  6%|██▍                                     | 77/1261 [00:32<08:02,  2.45it/s]\n",
      "  6%|██▍                                     | 78/1261 [00:33<08:03,  2.45it/s]\n",
      "  6%|██▌                                     | 79/1261 [00:33<08:21,  2.36it/s]\n",
      "  6%|██▌                                     | 80/1261 [00:34<08:25,  2.34it/s]\n",
      "  6%|██▌                                     | 81/1261 [00:34<08:27,  2.33it/s]\n",
      "  7%|██▌                                     | 82/1261 [00:34<08:06,  2.42it/s]\n",
      "  7%|██▋                                     | 83/1261 [00:35<08:00,  2.45it/s]\n",
      "  7%|██▋                                     | 84/1261 [00:35<08:10,  2.40it/s]\n",
      "  7%|██▋                                     | 85/1261 [00:36<08:05,  2.42it/s]\n",
      "  7%|██▋                                     | 86/1261 [00:36<07:52,  2.48it/s]\n",
      "  7%|██▊                                     | 87/1261 [00:36<07:47,  2.51it/s]\n",
      "  7%|██▊                                     | 88/1261 [00:37<07:48,  2.51it/s]\n",
      "  7%|██▊                                     | 89/1261 [00:37<08:04,  2.42it/s]\n",
      "  7%|██▊                                     | 90/1261 [00:38<08:10,  2.39it/s]\n",
      "  7%|██▉                                     | 91/1261 [00:38<08:04,  2.42it/s]\n",
      "  7%|██▉                                     | 92/1261 [00:38<07:51,  2.48it/s]\n",
      "  7%|██▉                                     | 93/1261 [00:39<07:38,  2.55it/s]\n",
      "  7%|██▉                                     | 94/1261 [00:39<07:48,  2.49it/s]\n",
      "  8%|███                                     | 95/1261 [00:40<07:44,  2.51it/s]\n",
      "  8%|███                                     | 96/1261 [00:40<08:50,  2.20it/s]\n",
      "  8%|███                                     | 97/1261 [00:41<09:10,  2.12it/s]\n",
      "  8%|███                                     | 98/1261 [00:41<08:45,  2.22it/s]\n",
      "  8%|███▏                                    | 99/1261 [00:41<08:23,  2.31it/s]\n",
      "  8%|███                                    | 100/1261 [00:42<07:58,  2.43it/s]\n",
      "  8%|███                                    | 101/1261 [00:42<07:48,  2.48it/s]\n",
      "  8%|███▏                                   | 102/1261 [00:43<07:39,  2.52it/s]\n",
      "  8%|███▏                                   | 103/1261 [00:43<07:36,  2.53it/s]\n",
      "  8%|███▏                                   | 104/1261 [00:43<07:37,  2.53it/s]\n",
      "  8%|███▏                                   | 105/1261 [00:44<07:29,  2.57it/s]\n",
      "  8%|███▎                                   | 106/1261 [00:44<07:33,  2.54it/s]\n",
      "  8%|███▎                                   | 107/1261 [00:45<07:28,  2.57it/s]\n",
      "  9%|███▎                                   | 108/1261 [00:45<07:35,  2.53it/s]\n",
      "  9%|███▎                                   | 109/1261 [00:45<07:50,  2.45it/s]\n",
      "  9%|███▍                                   | 110/1261 [00:46<08:06,  2.36it/s]\n",
      "  9%|███▍                                   | 111/1261 [00:46<08:13,  2.33it/s]\n",
      "  9%|███▍                                   | 112/1261 [00:47<08:23,  2.28it/s]\n",
      "  9%|███▍                                   | 113/1261 [00:47<09:17,  2.06it/s]\n",
      "  9%|███▌                                   | 114/1261 [00:48<09:31,  2.01it/s]\n",
      "  9%|███▌                                   | 115/1261 [00:48<08:58,  2.13it/s]\n",
      "  9%|███▌                                   | 116/1261 [00:49<08:26,  2.26it/s]\n",
      "  9%|███▌                                   | 117/1261 [00:49<08:10,  2.33it/s]\n",
      "  9%|███▋                                   | 118/1261 [00:49<08:16,  2.30it/s]\n",
      "  9%|███▋                                   | 119/1261 [00:50<07:46,  2.45it/s]\n",
      " 10%|███▋                                   | 120/1261 [00:50<07:39,  2.48it/s]\n",
      " 10%|███▋                                   | 121/1261 [00:51<07:31,  2.52it/s]\n",
      " 10%|███▊                                   | 122/1261 [00:51<07:37,  2.49it/s]\n",
      " 10%|███▊                                   | 123/1261 [00:51<07:43,  2.45it/s]\n",
      " 10%|███▊                                   | 124/1261 [00:52<07:41,  2.46it/s]\n",
      " 10%|███▊                                   | 125/1261 [00:52<07:31,  2.51it/s]\n",
      " 10%|███▉                                   | 126/1261 [00:53<07:27,  2.54it/s]\n",
      " 10%|███▉                                   | 127/1261 [00:53<07:28,  2.53it/s]\n",
      " 10%|███▉                                   | 128/1261 [00:53<07:42,  2.45it/s]\n",
      " 10%|███▉                                   | 129/1261 [00:54<07:40,  2.46it/s]\n",
      " 10%|████                                   | 130/1261 [00:54<08:50,  2.13it/s]\n",
      " 10%|████                                   | 131/1261 [00:55<09:41,  1.94it/s]\n",
      " 10%|████                                   | 132/1261 [00:56<10:36,  1.77it/s]\n",
      " 11%|████                                   | 133/1261 [00:56<09:52,  1.90it/s]\n",
      " 11%|████▏                                  | 134/1261 [00:57<09:21,  2.01it/s]\n",
      " 11%|████▏                                  | 135/1261 [00:57<09:28,  1.98it/s]\n",
      " 11%|████▏                                  | 136/1261 [00:58<08:59,  2.08it/s]\n",
      " 11%|████▏                                  | 137/1261 [00:58<08:37,  2.17it/s]\n",
      " 11%|████▎                                  | 138/1261 [00:58<08:23,  2.23it/s]\n",
      " 11%|████▎                                  | 139/1261 [00:59<08:18,  2.25it/s]\n",
      " 11%|████▎                                  | 140/1261 [00:59<08:01,  2.33it/s]\n",
      " 11%|████▎                                  | 141/1261 [01:00<07:53,  2.36it/s]\n",
      " 11%|████▍                                  | 142/1261 [01:00<07:58,  2.34it/s]\n",
      " 11%|████▍                                  | 143/1261 [01:00<07:51,  2.37it/s]\n",
      " 11%|████▍                                  | 144/1261 [01:01<07:37,  2.44it/s]\n",
      " 11%|████▍                                  | 145/1261 [01:01<07:41,  2.42it/s]\n",
      " 12%|████▌                                  | 146/1261 [01:02<08:33,  2.17it/s]\n",
      " 12%|████▌                                  | 147/1261 [01:02<08:24,  2.21it/s]\n",
      " 12%|████▌                                  | 148/1261 [01:03<08:04,  2.30it/s]\n",
      " 12%|████▌                                  | 149/1261 [01:03<08:05,  2.29it/s]"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "white_output = 'project_video_run4.mp4'\n",
    "clip1 = VideoFileClip('./Input Videos/project_video.mp4')\n",
    "white_clip = clip1.fl_image(process_frame) #NOTE: this function expects color images!!\n",
    "\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
