{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the image from the source folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "test_images=os.listdir('../test_images')\n",
    "image=test_images[3]\n",
    "img=cv2.imread('../test_images/'+image)\n",
    "gray_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Calibrate and undistort the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cal_undistort_image(img, objPts = objpoints, imgPts = imgpoints):\n",
    "    \"\"\"\n",
    "    returns the undistorted image\n",
    "    \"\"\"\n",
    "    ret,camera_matrix,distortion_coefficients,rotational_vectors,tangential_vectors=cv2.calibrateCamera(objPts,imgPts,gray_img.shape[0:2],None,None)\n",
    "    undistort_img = cv2.undistort(img,camera_matrix,distortion_coefficients,None,camera_matrix)\n",
    "    return undistort_img\n",
    "\n",
    "def hls_to_s(img):\n",
    "    \"\"\"\n",
    "    returns a 2D image ie the s channel of the HLS image\n",
    "    \"\"\"\n",
    "    hls=cv2.cvtColor(img,cv2.COLOR_BGR2HLS) \n",
    "    mask=np.zeros_like(hls[:,:,0])\n",
    "    #thresholding the pixel values of the mask\n",
    "    mask[(hls[:,:,2] > 100) & (hls[:,:,0]<100)]=1\n",
    "    s_channel=mask\n",
    "    return s_channel\n",
    "\n",
    "def absolute_sobel(img,orientation='x',sobel_kernel=3,thresh=(20,100)):\n",
    "    \"\"\"\n",
    "    returns a binary thresholded image with sobel gradients\n",
    "    \"\"\"\n",
    "    #taking sobel gradient \n",
    "    if orientation=='x':\n",
    "        sobel_img=cv2.Sobel(img,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    elif orientation=='y':\n",
    "        sobel_img=cv2.Sobel(img,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    #finding the absolute value     \n",
    "    abs_sobel=np.absolute(sobel_img) \n",
    "    #scaling the pixel values to 8 bit\n",
    "    scaled_sobel_img=np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    #create a binary image with zero values\n",
    "    binary_threshold=np.zeros_like(scaled_sobel_img)\n",
    "    # change the zero values to ones where thresholding condition is met\n",
    "    binary_threshold[(scaled_sobel_img >= thresh[0]) & (scaled_sobel_img <= thresh[1])]=1\n",
    "    return binary_threshold\n",
    "\n",
    "def mag_thresh(img,sobel_kernel=5,thresh=(30,100)):\n",
    "    \"\"\"\n",
    "    This returns the binary thresholded image with both x and y sobel gradients\n",
    "    \"\"\"\n",
    "    #taking sobel x gradient\n",
    "    sobelx=cv2.Sobel(img,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    #taking sobel y gradient\n",
    "    sobely=cv2.Sobel(img,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    #calculating the gradient magnitude\n",
    "    abs_mag_sobel=np.absolute(np.sqrt(sobelx**2 + sobely**2))\n",
    "    #scaling the pixel values to 8 bit\n",
    "    scaled_sobel=np.uint8(255*abs_mag_sobel/np.max(abs_mag_sobel))\n",
    "    #create a binary image with zero values\n",
    "    binary_threshold=np.zeros_like(scaled_sobel)\n",
    "    # change the zero values to ones where thresholding condition is met\n",
    "    binary_threshold[(scaled_sobel >= thresh[0]) & (scaled_sobel <=thresh[1])]=1\n",
    "    return binary_threshold\n",
    "\n",
    "def dir_thresh(img,sobel_kernel=5,thresh=(0.7,1.3)):\n",
    "    \"\"\"\n",
    "    This returns the binary image with thresholded angled sobel gradients\n",
    "    \"\"\"\n",
    "    #taking sobel x gradient\n",
    "    sobelx=cv2.Sobel(img,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    #taking sobel y gradient\n",
    "    sobely=cv2.Sobel(img,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    #getting the sobel gradients based on the direction\n",
    "    dir_grad=np.arctan2(np.absolute(sobely),np.absolute(sobelx))\n",
    "    #create a binary image with zero values\n",
    "    binary_threshold=np.zeros_like(dir_grad)\n",
    "    # change the zero values to ones where thresholding condition is met\n",
    "    binary_threshold[(dir_grad >= thresh[0]) & (dir_grad <=thresh[1] )]=1\n",
    "    return binary_threshold\n",
    "\n",
    "def perform_perspective_transform(img,img_size):\n",
    "    \"\"\"\n",
    "    This returns the warped image ie a bird's eye view \n",
    "    \"\"\"\n",
    "    #the source coordinates on the image to be taken in consideration for a transform\n",
    "    src = np.array([[585, 460], [203, 720], [1127, 720], [695, 460]]).astype(np.float32)\n",
    "    #the sestination coordinates on the image to be taken in consideration for warping\n",
    "    dst = np.array([[320, 0], [320, 720], [960, 720], [960, 0]]).astype(np.float32)\n",
    "    #returns a transform matrix M\n",
    "    M=cv2.getPerspectiveTransform(src,dst)\n",
    "    #a warped image is returned\n",
    "    warped=cv2.warpPerspective(img,M,img_size,flags=cv2.INTER_LINEAR)\n",
    "    return warped\n",
    " \n",
    "def perform_inverse_perspective_transform(img,img_size):\n",
    "    \"\"\"\n",
    "    This returns the original image from the transformed image\n",
    "    \"\"\"\n",
    "    src = np.array([[585, 460], [203, 720], [1127, 720], [695, 460]]).astype(np.float32)\n",
    "    dst = np.array([[320, 0], [320, 720], [960, 720], [960, 0]]).astype(np.float32)\n",
    "    M=cv2.getPerspectiveTransform(dst,src)\n",
    "    #the original image is returned\n",
    "    original=cv2.warpPerspective(img,M,img_size,flags=cv2.INTER_LINEAR)\n",
    "    return original    \n",
    "\n",
    "\n",
    "def hls_sobel_mask(img):\n",
    "    \"\"\"\n",
    "     Applies the HLS and sobel masks to the image\n",
    "    \"\"\"\n",
    "    #take a copy of the image\n",
    "    img = img.copy()\n",
    "    #convert image to grayscale\n",
    "    gray_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #convert image to HLS\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    # Apply a mask on HLS colour channels\n",
    "    mask = np.zeros_like(hls[:, :, 0])\n",
    "    # This selects pixels with higher than 100 saturation and lower than 100 hue\n",
    "    mask[((hls[:, :, 2] > 100) & (hls[:, :, 0] < 100) ) ] = 1\n",
    "    # Apply a sobel magnitude threshold\n",
    "    # I apply a more lenient mag_thresh to the upper part of the transformed image, as this part is blurrier\n",
    "    # and will therefore have smoother gradients.\n",
    "    # On the bottom half, this selects pixels with >10 sobel magnitude, and on the top half, \n",
    "    # selects pixels with >35 sobel magnitude\n",
    "    upper_mag = mag_thresh(gray_img, 3, (10, 255))\n",
    "    lower_mag = mag_thresh(gray_img, 3, (35, 255))\n",
    "    \n",
    "    mag_mask = np.zeros_like(lower_mag)\n",
    "    mag_mask[:int(mag_mask.shape[0]/2), :] = upper_mag[:int(mag_mask.shape[0]/2), :]\n",
    "    mag_mask[int(mag_mask.shape[0]/2):, :] = lower_mag[int(mag_mask.shape[0]/2):, :]\n",
    "    \n",
    "    # Use the bitwise OR mask of both masks for the final mask\n",
    "    final_mask = np.maximum(mag_mask, mask)\n",
    "\n",
    "    # Return the transformed mask\n",
    "    return final_mask                        \n",
    "\n",
    "def find_peaks(final_mask):\n",
    "    \"\"\"\n",
    "    Returns the inices of the left and right lanes\n",
    "    \"\"\"\n",
    "    #finding the size of the image\n",
    "    shape=final_mask.shape\n",
    "    #taking the bottom section of image under consideration\n",
    "    bottom_section=final_mask[-int(shape[0]/2):,]\n",
    "    \n",
    "    \n",
    "    #the left peak ie the indices or x position of left lane\n",
    "    left_peak=bottom_section[:,:int(shape[1]/2)].sum(axis=0).argmax()\n",
    "    #the right peak ie the indices or the x position of right lane\n",
    "    right_peak=bottom_section[:,int(shape[1]/2):].sum(axis=0).argmax() + int(shape[1]/2)\n",
    "\n",
    "    return left_peak,right_peak\n",
    "                        \n",
    "def window_search(final_mask,left_peak,right_peak,no_of_strips=10,margin=80):\n",
    "    \"\"\"\n",
    "    This applies the sliding window approach to find lane pixels, and then fits a polynomial to the found pixels.\n",
    "    \"\"\"\n",
    "    #creating an array of windows or strips ie dividing the image into vertical windows or strips\n",
    "    strips=[]\n",
    "    assert final_mask.shape[0] % no_of_strips==0 , 'No of strips should be a factor of height of the image ie vertical resolution'\n",
    "    #size or width of the strip\n",
    "    width_of_strip=final_mask.shape[0]/no_of_strips\n",
    "    for i in range(no_of_strips):\n",
    "        strip=final_mask[i*width_of_strip:(i+1)*width_of_strip,:]\n",
    "        strips.append(strip)\n",
    "    # reverse theorder of strips ie start from the bottom to top        \n",
    "    strips=strips[::-1]\n",
    "    #store x positions of left lane \n",
    "    lefts=[left_peak]\n",
    "    #store x positions of right lane \n",
    "    rights=[right_peak]\n",
    "    left_px=[]\n",
    "    left_py=[]\n",
    "    right_px=[]\n",
    "    right_py =[]\n",
    "    for i ,strip in enumerate(strips):\n",
    "        offset=(no_of_strips -i-1)*width_of_strip\n",
    "        last_left=int(lefts[-1])\n",
    "        last_right=int(rights[-1])\n",
    "        # Only consider pixels within +-leeway of last strip location\n",
    "        temp_left_strip=strip.copy()\n",
    "        temp_left_strip[:, :last_left-margin]=0\n",
    "        temp_left_strip[:,last_left+margin:]=0\n",
    "        \n",
    "        temp_right_strip=strip.copy()\n",
    "        temp_right_strip[:,:last_right-margin]=0\n",
    "        temp_right_strip[:,last_right+margin:]=0\n",
    "        # Save the x, y pixel indexes for calculating the polynomial\n",
    "        left_px.append(temp_left_strip.nonzero()[1])\n",
    "        left_py.append(temp_left_strip.nonzero()[0] + offset)\n",
    "        \n",
    "        right_px.append(temp_right_strip.nonzero()[1])\n",
    "        right_py.append(temp_right_strip.nonzero()[0] + offset)\n",
    "    # Create x and y indice arrays for both lines\n",
    "    left_px=np.concatenate(left_px)\n",
    "    left_py=np.concatenate(left_py)\n",
    "    right_px=np.concatenate(right_px)\n",
    "    right_py=np.concatenate(right_py)\n",
    "    # Fit the polynomials!\n",
    "    left_poly=np.polyfit(left_py,left_px,2)\n",
    "    right_poly=np.polyfit(right_py,right_px,2)\n",
    "    \n",
    "    return left_poly,right_poly\n",
    "\n",
    "def plot_polygon(img_original,img_size,left_poly,right_poly):\n",
    "    \"\"\"\n",
    "    Plot the polygon on the images\n",
    "    \"\"\"\n",
    "    plot_y=np.linspace(0,img_original.shape[0]-1,img_original.shape[0])\n",
    "    left_fit=left_poly[0]*plot_y**2 + left_poly[1]*plot_y + left_poly[2]\n",
    "    right_fit=right_poly[0]*plot_y**2 +right_poly[1]*plot_y + right_poly[2]\n",
    "    \n",
    "    pts_left=np.array([np.transpose(np.vstack([left_fit,plot_y]))])\n",
    "    pts_right=np.array([np.flipud(np.transpose(np.vstack([right_fit,plot_y])))])\n",
    "    pts=np.hstack((pts_left,pts_right))\n",
    "    # Create an overlay from the lane lines\n",
    "    overlay_mask=np.zeros_like(img_original).astype(np.uint8)\n",
    "   \n",
    "    cv2.fillPoly(overlay_mask,np.int_([pts]),(0,255,0))\n",
    "    # Apply inverse transform to the overlay to plot it on the original road\n",
    "    overlay_mask=perform_inverse_perspective_transform(overlay_mask,img_size)\n",
    "    \n",
    "    return cv2.addWeighted(img_original,1,overlay_mask,0.3,0)\n",
    "\n",
    "def find_curvature(poly,final_mask):\n",
    "    yscale = 30 / 720 # Real world metres per y pixel\n",
    "    xscale = 3.7 / 700 # Real world metres per x pixel\n",
    "    \n",
    "    # Convert polynomial to set of points for refitting\n",
    "    ploty = np.linspace(0, final_mask.shape[0]-1, final_mask.shape[0])\n",
    "    fitx = poly[0] * ploty ** 2 + poly[1] * ploty + poly[2]\n",
    "    \n",
    "    # Fit new polynomial\n",
    "    fit_cr = np.polyfit(ploty * yscale, fitx * xscale, 2)\n",
    "    \n",
    "    # Calculate curve radius\n",
    "    curverad = ((1 + (2 * fit_cr[0] * np.max(ploty) * yscale + fit_cr[1]) ** 2) ** 1.5) / np.absolute(2 * fit_cr[0])\n",
    "    return curverad\n",
    "\n",
    "def find_offset(l_poly,r_poly):\n",
    "    #assuming camera is installed at the center of the car dashboard\n",
    "    lane_width=3.7 #in metres\n",
    "    h=720\n",
    "    w=1280\n",
    "    bottom_point_left=l_poly[0]*h**2 + l_poly[1]*h + l_poly[2]\n",
    "    bottom_point_right=r_poly[0]*h**2 + r_poly[1]*h + r_poly[2]\n",
    "    \n",
    "    # no of pixels per metre\n",
    "    meter_scale=lane_width/np.absolute(bottom_point_right -bottom_point_left)\n",
    "    \n",
    "    #midpoint in between  the lanes\n",
    "    midpoint=np.mean([bottom_point_left,bottom_point_right])\n",
    "    \n",
    "    #offset between the camera and the lane center\n",
    "    \n",
    "    offset=(w/2 - midpoint) * meter_scale\n",
    "    \n",
    "    return offset\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_rad=None\n",
    "last_left_poly=None\n",
    "last_right_poly=None\n",
    "def process_frame(img):\n",
    "    global last_rad,last_left_poly,last_right_poly\n",
    "    \n",
    "    #weights for smoothing\n",
    "    rad_factor=0.03\n",
    "    poly_factor=0.3\n",
    "    \n",
    "    #undistorting the frame image\n",
    "    undistort=cal_undistort_image(img) \n",
    "   \n",
    "    #create image copy\n",
    "    orig_img=undistort.copy()\n",
    "    \n",
    "    img_size=(undistort.shape[1],undistort.shape[0])\n",
    "    #perform warping of the image\n",
    "    warped=perform_perspective_transform(undistort,img_size)\n",
    "    \n",
    "    combined_binary_thresh =hls_sobel_mask(warped)\n",
    "    \n",
    "    #finding the lane lines x positions\n",
    "    l,r=find_peaks(combined_binary_thresh)#\n",
    "    #finding the coefficeints of polynomials fitting the lane lines\n",
    "    l_poly,r_poly = window_search(combined_binary_thresh,l,r)\n",
    "    \n",
    "    \n",
    "    if last_left_poly is None:\n",
    "        last_left_poly=l_poly\n",
    "        last_right_poly=r_poly\n",
    "    else:\n",
    "        l_poly=(1-poly_factor)* last_left_poly + (poly_factor) * l_poly\n",
    "        r_poly=(1-poly_factor)*last_right_poly +(poly_factor) * r_poly\n",
    "        last_left_poly=l_poly\n",
    "        last_right_poly=r_poly\n",
    "    \n",
    "    #finding the curvature of the road\n",
    "    \n",
    "    l_rad=find_curvature(l_poly,combined_binary_thresh)\n",
    "    r_rad=find_curvature(r_poly,combined_binary_thresh)\n",
    "    rad=np.mean([l_rad,r_rad])\n",
    "    \n",
    "    if last_rad is None:\n",
    "        last_rad=rad\n",
    "    else:\n",
    "        rad=(1-rad_factor) *rad + rad_factor * last_rad\n",
    "    #plot the polygon\n",
    "    result=plot_polygon(orig_img, (combined_binary_thresh.shape[1],combined_binary_thresh.shape[0]),l_poly,r_poly)\n",
    "    \n",
    "     # Write radius on image\n",
    "    cv2.putText(result, 'Lane Radius: {}m'.format(int(last_rad)), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, 255)\n",
    "    offset=find_offset(l_poly,r_poly)\n",
    "    \n",
    "    #Write lane offset on frame\n",
    "    cv2.putText(result,'Lane Offset: {}m'.format(int(offset)),(10,100),cv2.FONT_HERSHEY_SIMPLEX,1.5,255)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Me\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\ipykernel\\__main__.py:158: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[194, 158, 112],\n",
       "        [194, 158, 112],\n",
       "        [194, 158, 112],\n",
       "        ..., \n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[193, 157, 111],\n",
       "        [194, 158, 112],\n",
       "        [194, 158, 112],\n",
       "        ..., \n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[193, 157, 111],\n",
       "        [194, 158, 112],\n",
       "        [194, 158, 112],\n",
       "        ..., \n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       ..., \n",
       "       [[ 78,  86, 106],\n",
       "        [ 84,  92, 112],\n",
       "        [ 88,  97, 117],\n",
       "        ..., \n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[ 79,  88, 108],\n",
       "        [ 82,  91, 111],\n",
       "        [ 86,  95, 115],\n",
       "        ..., \n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[ 80,  89, 109],\n",
       "        [ 79,  88, 108],\n",
       "        [ 79,  88, 108],\n",
       "        ..., \n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_frame(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_run4.mp4\n",
      "[MoviePy] Writing video project_video_run4.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|████████████████████▊                  | 674/1261 [04:00<03:31,  2.78it/s]"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "white_output = 'project_video_run4.mp4'\n",
    "clip1 = VideoFileClip('../project_video.mp4')\n",
    "white_clip = clip1.fl_image(process_frame) #NOTE: this function expects color images!!\n",
    "\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
